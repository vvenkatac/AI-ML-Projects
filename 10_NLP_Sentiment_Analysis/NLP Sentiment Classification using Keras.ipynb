{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of SeqNLP_Project1_Questions-1.ipynb","provenance":[{"file_id":"1GJN5lLXgW_M64W_ij-tivUk01TwScC4O","timestamp":1616664664284}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xT7MKZuMRaCg"},"source":["# NLP - Sentiment Classification\n"]},{"cell_type":"markdown","metadata":{"id":"aJpFmOHGShfH"},"source":["## Overview/Context\n","- Generate Word Embedding and retrieve outputs of each layer with Keras based on the Classification task.\n","- Word embedding are a type of word representation that allows words with similar meaning to have a similar representation.\n","- It is a distributed representation for the text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging natural language processing problems.\n","- We will use the IMDb dataset to learn word embedding as we train our dataset.\n","- This dataset contains 25,000 movie reviews from IMDB, labeled with a sentiment (positive or negative)."]},{"cell_type":"markdown","metadata":{"id":"ySW1gscvShfH"},"source":["## About the Data\n","- The Dataset of 25,000 movie reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers).\n","- For convenience, the words are indexed by their frequency in the dataset, meaning the for that has index 1 is the most frequent word.\n","- Use the first 20 words from each review to speed up training, using a max vocab size of 10,000.\n","- As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word."]},{"cell_type":"markdown","metadata":{"id":"xtkf9fgqShfI"},"source":["### Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8Pw6JT8ShfI","executionInfo":{"status":"ok","timestamp":1616663365966,"user_tz":-330,"elapsed":27175,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}},"outputId":"c13c30f5-f626-44a5-f516-f9ed98c8f51c"},"source":["# Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AFPhLFX0TWc2","executionInfo":{"status":"ok","timestamp":1616663371771,"user_tz":-330,"elapsed":3748,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}}},"source":["# Setting the current working directory\n","import os; os.chdir('drive/My Drive/Projects/NLP/Sentiment Classification')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-xuvVVuVUilm"},"source":["## Import Required Packages"]},{"cell_type":"code","metadata":{"id":"s_7gjASoUmO9","executionInfo":{"status":"ok","timestamp":1616663392600,"user_tz":-330,"elapsed":2454,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}}},"source":["# Import packages\n","import pandas as pd, numpy as np\n","import tensorflow as tf\n","assert tf.__version__ >= '2.0'\n","\n","from itertools import islice\n","\n","# Keras\n","from keras.layers import Dense, Embedding, LSTM, Dropout, MaxPooling1D, Conv1D\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Model, Sequential\n","from keras.preprocessing import sequence\n","from keras.datasets import imdb\n","\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","# Suppress warnings\n","import warnings; warnings.filterwarnings('ignore')\n","\n","random_state = 40\n","np.random.seed(random_state)\n","tf.random.set_seed(random_state)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wq4RCyyPSYRp"},"source":["### Loading the dataset "]},{"cell_type":"code","metadata":{"id":"NGCtiXUhSWss","executionInfo":{"status":"ok","timestamp":1616663500309,"user_tz":-330,"elapsed":7667,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}}},"source":["from keras.datasets import imdb\n","\n","vocab_size = 10000 #vocab size\n","\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency."],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"fCPC_WN-eCyw"},"source":["from keras.preprocessing.sequence import pad_sequences\n","vocab_size = 10000 #vocab size\n","maxlen = 300  #number of word used from each review"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qMEsHYrWxdtk"},"source":["## Train test split "]},{"cell_type":"code","metadata":{"id":"h0g381XzeCyz"},"source":["#load dataset as a list of ints\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n","#make all sequences of the same length\n","x_train = pad_sequences(x_train, maxlen = maxlen, padding = 'pre')\n","x_test =  pad_sequences(x_test, maxlen = maxlen, padding = 'pre')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jy6n-uM2eCy2"},"source":["X = np.concatenate((x_train, x_test), axis = 0)\n","y = np.concatenate((y_train, y_test), axis = 0)\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state, shuffle = True)\n","x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.2, random_state = random_state, shuffle = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZhMAgaNeCy5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616329703129,"user_tz":-330,"elapsed":1615,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}},"outputId":"dd3a3ea5-aee6-4beb-8a32-9abf7851f63e"},"source":["print('---'*20, f'\\nNumber of rows in training dataset: {x_train.shape[0]}')\n","print(f'Number of columns in training dataset: {x_train.shape[1]}')\n","print(f'Number of unique words in training dataset: {len(np.unique(np.hstack(x_train)))}')\n","\n","\n","print('---'*20, f'\\nNumber of rows in validation dataset: {x_valid.shape[0]}')\n","print(f'Number of columns in validation dataset: {x_valid.shape[1]}')\n","print(f'Number of unique words in validation dataset: {len(np.unique(np.hstack(x_valid)))}')\n","\n","\n","print('---'*20, f'\\nNumber of rows in test dataset: {x_test.shape[0]}')\n","print(f'Number of columns in test dataset: {x_test.shape[1]}')\n","print(f'Number of unique words in test dataset: {len(np.unique(np.hstack(x_test)))}')\n","\n","\n","print('---'*20, f'\\nUnique Categories: {np.unique(y_train), np.unique(y_valid), np.unique(y_test)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------------------------------------------------------ \n","Number of rows in training dataset: 32000\n","Number of columns in training dataset: 300\n","Number of unique words in training dataset: 9999\n","------------------------------------------------------------ \n","Number of rows in validation dataset: 8000\n","Number of columns in validation dataset: 300\n","Number of unique words in validation dataset: 9986\n","------------------------------------------------------------ \n","Number of rows in test dataset: 10000\n","Number of columns in test dataset: 300\n","Number of unique words in test dataset: 9986\n","------------------------------------------------------------ \n","Unique Categories: (array([0, 1]), array([0, 1]), array([0, 1]))\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S3J_18Sfwmdz"},"source":["##Get word index and create a key-value pair for word and word id\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OT5kreSSZWV7","executionInfo":{"status":"ok","timestamp":1616331749752,"user_tz":-330,"elapsed":1071,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}},"outputId":"02bbce50-6397-42ae-c620-592a4c446d86"},"source":[" def decode_review(x, y):\n","  w2i = imdb.get_word_index()                                \n","  w2i = {k:(v + 3) for k, v in w2i.items()}\n","  w2i['<PAD>'] = 0\n","  w2i['<START>'] = 1\n","  w2i['<UNK>'] = 2\n","  i2w = {i: w for w, i in w2i.items()}\n","\n","  ws = (' '.join(i2w[i] for i in x))\n","  print(f'Review: {ws}')\n","  print(f'Actual Sentiment: {y}')\n","  return w2i, i2w\n","\n","w2i, i2w = decode_review(x_train[0], y_train[0])\n","\n","# get first 50 key, value pairs from id to word dictionary\n","print('---'*30, '\\n', list(islice(i2w.items(), 0, 50)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Review: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> i first caught up with jennifer years ago while out of town when it showed up on tv in the middle of the night i fell asleep before it ended but it stuck with me until i had to track it down its appeal is that though there's not a lot to it it weaves an intriguing atmosphere and because <UNK> <UNK> and howard duff real life man and wife at the time display an <UNK> low key chemistry <UNK> plays a woman engaged to house sit a vast california estate whose previous caretaker jennifer up and disappeared shades of jack nicholson in the shining although in this instance it's not <UNK> who goes or went mad duff is the guy in town who manages the <UNK> <UNK> and takes a shine to <UNK> who decides to play hard to get she becomes more and more involved not to say obsessed with what happened to her predecessor in the old dark house full of <UNK> and locked the <UNK> and the romantic <UNK> are by far the best part of the movie as viewers are likely to find the resolution a bit of a letdown there's just not that much to it except a little <UNK> at the tail end that <UNK> brian de palma's <UNK> but it's well done and again it sticks with you extra added attraction this is the film that introduced the song angel eyes which would become part of the standard <UNK> of ol' blue eyes\n","Actual Sentiment: 1\n","------------------------------------------------------------------------------------------ \n"," [(34704, 'fawn'), (52009, 'tsukino'), (52010, 'nunnery'), (16819, 'sonja'), (63954, 'vani'), (1411, 'woods'), (16118, 'spiders'), (2348, 'hanging'), (2292, 'woody'), (52011, 'trawling'), (52012, \"hold's\"), (11310, 'comically'), (40833, 'localized'), (30571, 'disobeying'), (52013, \"'royale\"), (40834, \"harpo's\"), (52014, 'canet'), (19316, 'aileen'), (52015, 'acurately'), (52016, \"diplomat's\"), (25245, 'rickman'), (6749, 'arranged'), (52017, 'rumbustious'), (52018, 'familiarness'), (52019, \"spider'\"), (68807, 'hahahah'), (52020, \"wood'\"), (40836, 'transvestism'), (34705, \"hangin'\"), (2341, 'bringing'), (40837, 'seamier'), (34706, 'wooded'), (52021, 'bravora'), (16820, 'grueling'), (1639, 'wooden'), (16821, 'wednesday'), (52022, \"'prix\"), (34707, 'altagracia'), (52023, 'circuitry'), (11588, 'crotch'), (57769, 'busybody'), (52024, \"tart'n'tangy\"), (14132, 'burgade'), (52026, 'thrace'), (11041, \"tom's\"), (52028, 'snuggles'), (29117, 'francesco'), (52030, 'complainers'), (52128, 'templarios'), (40838, '272')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dybtUgUReCy8"},"source":["## Build Keras Embedding Layer Model (30 points)\n","We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n","\n","* The embedding layer can be used at the start of a larger deep learning model. \n","* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n","* Use the embedding layer to train our own word2vec models.\n","\n","The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."]},{"cell_type":"code","metadata":{"id":"A5OLM4eBeCy9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616331796770,"user_tz":-330,"elapsed":6484,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}},"outputId":"3dbd1c4a-981d-471d-cd4b-1d7377c00666"},"source":["model = Sequential()\n","model.add(Embedding(vocab_size, 256, input_length = maxlen))\n","model.add(Dropout(0.25))\n","model.add(Conv1D(256, 5, padding = 'same', activation = 'relu', strides = 1))\n","model.add(Conv1D(128, 5, padding = 'same', activation = 'relu', strides = 1))\n","model.add(MaxPooling1D(pool_size = 2))\n","model.add(Conv1D(64, 5, padding = 'same', activation = 'relu', strides = 1))\n","model.add(MaxPooling1D(pool_size = 2))\n","model.add(LSTM(75))\n","model.add(Dense(1, activation = 'sigmoid'))\n","model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","print(model.summary())\n","\n","# Adding callbacks\n","es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 0)  \n","mc = ModelCheckpoint('imdb_model.h5', monitor = 'val_loss', mode = 'min', save_best_only = True, verbose = 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 300, 256)          2560000   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 300, 256)          0         \n","_________________________________________________________________\n","conv1d (Conv1D)              (None, 300, 256)          327936    \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 300, 128)          163968    \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 150, 128)          0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 150, 64)           41024     \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 75, 64)            0         \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 75)                42000     \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 76        \n","=================================================================\n","Total params: 3,135,004\n","Trainable params: 3,135,004\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TxNDNhrseCzA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616331917457,"user_tz":-330,"elapsed":94017,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}},"outputId":"8a258e6e-9a56-4b1d-c0c9-c1cb6883e941"},"source":["# Fit the model\n","model.fit(x_train, y_train, validation_data = (x_valid, y_valid), epochs = 3, batch_size = 64, verbose = True, callbacks = [es, mc])\n","\n","# Evaluate the model\n","scores = model.evaluate(x_test, y_test, batch_size = 64)\n","print('Test accuracy: %.2f%%' % (scores[1]*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","500/500 [==============================] - 62s 57ms/step - loss: 0.4776 - accuracy: 0.7214 - val_loss: 0.2563 - val_accuracy: 0.8946\n","\n","Epoch 00001: val_loss improved from inf to 0.25631, saving model to imdb_model.h5\n","Epoch 2/3\n","500/500 [==============================] - 28s 57ms/step - loss: 0.1772 - accuracy: 0.9332 - val_loss: 0.2599 - val_accuracy: 0.8950\n","\n","Epoch 00002: val_loss did not improve from 0.25631\n","Epoch 00002: early stopping\n","157/157 [==============================] - 2s 14ms/step - loss: 0.2443 - accuracy: 0.9026\n","Test accuracy: 90.26%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L3CSVVPPeCzD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616332011634,"user_tz":-330,"elapsed":3314,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}},"outputId":"14927e69-4c7a-4549-f1fc-32876ab89bb5"},"source":["y_pred = model.predict_classes(x_test)\n","print(f'Classification Report:\\n{classification_report(y_pred, y_test)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.88      0.90      5208\n","           1       0.87      0.93      0.90      4792\n","\n","    accuracy                           0.90     10000\n","   macro avg       0.90      0.90      0.90     10000\n","weighted avg       0.90      0.90      0.90     10000\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Igq8Qm8GeCzG"},"source":["## Accuracy of the model  & Retrive the output of each layer in keras for a given single test sample from the trained model you built "]},{"cell_type":"code","metadata":{"id":"0AqOnLa2eCzH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616332069851,"user_tz":-330,"elapsed":2106,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}},"outputId":"dd2c4d13-769a-44be-a5db-eb6631c3bb0f"},"source":["sample_x_test = x_test[np.random.randint(10000)]\n","for layer in model.layers:\n","\n","    model_layer = Model(inputs = model.input, outputs = model.get_layer(layer.name).output)\n","    output = model_layer.predict(sample_x_test.reshape(1,-1))\n","    print('\\n','--'*20, layer.name, 'layer', '--'*20, '\\n')\n","    print(output)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," ---------------------------------------- embedding layer ---------------------------------------- \n","\n","[[[-0.00984982  0.02402639  0.00732345 ...  0.01935286  0.0317665\n","   -0.00632548]\n","  [-0.00984982  0.02402639  0.00732345 ...  0.01935286  0.0317665\n","   -0.00632548]\n","  [-0.00984982  0.02402639  0.00732345 ...  0.01935286  0.0317665\n","   -0.00632548]\n","  ...\n","  [-0.02441969 -0.00658704 -0.05887107 ... -0.01739137  0.04956373\n","    0.00547364]\n","  [-0.0294162   0.02436043  0.01181066 ...  0.03686921 -0.04653443\n","    0.0048245 ]\n","  [ 0.02370638 -0.01012601  0.11731517 ...  0.09650249 -0.02937531\n","    0.06121516]]]\n","\n"," ---------------------------------------- dropout layer ---------------------------------------- \n","\n","[[[-0.00984982  0.02402639  0.00732345 ...  0.01935286  0.0317665\n","   -0.00632548]\n","  [-0.00984982  0.02402639  0.00732345 ...  0.01935286  0.0317665\n","   -0.00632548]\n","  [-0.00984982  0.02402639  0.00732345 ...  0.01935286  0.0317665\n","   -0.00632548]\n","  ...\n","  [-0.02441969 -0.00658704 -0.05887107 ... -0.01739137  0.04956373\n","    0.00547364]\n","  [-0.0294162   0.02436043  0.01181066 ...  0.03686921 -0.04653443\n","    0.0048245 ]\n","  [ 0.02370638 -0.01012601  0.11731517 ...  0.09650249 -0.02937531\n","    0.06121516]]]\n","\n"," ---------------------------------------- conv1d layer ---------------------------------------- \n","\n","[[[0.         0.         0.         ... 0.         0.         0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]\n","  ...\n","  [0.196446   0.29948825 0.19833884 ... 0.27079007 0.19010669 0.40704316]\n","  [0.2878968  0.35897377 0.08962449 ... 0.5312228  0.06238239 0.19844018]\n","  [0.27561042 0.24613479 0.11829738 ... 0.09833437 0.         0.25233597]]]\n","WARNING:tensorflow:5 out of the last 317 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8a13b2d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\n"," ---------------------------------------- conv1d_1 layer ---------------------------------------- \n","\n","[[[0.         0.         0.         ... 0.         0.         0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]\n","  ...\n","  [1.3788397  1.6990697  0.         ... 0.         1.4825561  0.        ]\n","  [0.736477   1.249557   0.         ... 0.         0.20723596 0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]]]\n","WARNING:tensorflow:6 out of the last 318 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe89a915b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\n"," ---------------------------------------- max_pooling1d layer ---------------------------------------- \n","\n","[[[0.         0.         0.         ... 0.         0.         0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]\n","  ...\n","  [1.3617487  0.47936514 0.         ... 0.         1.4858693  0.        ]\n","  [1.3788397  1.6990697  0.         ... 0.         1.4825561  0.        ]\n","  [0.736477   1.249557   0.         ... 0.         0.20723596 0.        ]]]\n","WARNING:tensorflow:7 out of the last 319 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe89dec1cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\n"," ---------------------------------------- conv1d_2 layer ---------------------------------------- \n","\n","[[[0.        0.        0.        ... 0.        0.        0.       ]\n","  [0.        0.        0.        ... 0.        0.        0.       ]\n","  [0.        0.        0.        ... 0.        0.        0.       ]\n","  ...\n","  [0.        0.        0.        ... 0.        0.        0.       ]\n","  [0.        0.        0.        ... 0.        0.4364421 0.       ]\n","  [0.        0.        0.        ... 0.        0.        0.       ]]]\n","WARNING:tensorflow:8 out of the last 320 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8987a13b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\n"," ---------------------------------------- max_pooling1d_1 layer ---------------------------------------- \n","\n","[[[0.         0.         0.         ... 0.         0.         0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]\n","  ...\n","  [0.         0.         0.         ... 0.         0.31117806 0.        ]\n","  [0.         0.         0.         ... 0.         0.         0.        ]\n","  [0.         0.         0.         ... 0.         0.4364421  0.        ]]]\n","WARNING:tensorflow:9 out of the last 321 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8987a1200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\n"," ---------------------------------------- lstm layer ---------------------------------------- \n","\n","[[-6.0880851e-02 -1.9651975e-01  7.0786658e-03 -1.2546976e-01\n","   2.1267828e-01 -2.6831090e-01 -4.8153400e-01  2.0765339e-01\n","   5.7746634e-02 -3.2534882e-02  5.2194077e-01  2.0739088e-02\n","   1.5312324e-01  4.5569515e-01 -5.9816748e-01 -1.2704721e-01\n","   6.0899282e-01  2.7080587e-01  2.3499478e-01 -2.5325377e-02\n","  -3.3680864e-02  2.1336097e-02  5.2331948e-01  3.2482218e-04\n","  -4.1345471e-01 -3.5589966e-01 -1.1682849e-01  3.8376760e-01\n","  -4.7684851e-01 -1.3148329e-01 -3.2017541e-01  1.7428488e-02\n","  -2.3110069e-02  5.5918062e-01 -3.0198675e-01 -1.2356143e-01\n","   9.7413905e-02  1.7524473e-01 -3.0907881e-01 -3.5424936e-01\n","   2.5472251e-01  8.8243097e-02 -1.3872141e-01  2.7075136e-01\n","  -2.9758887e-02 -5.9117156e-01 -5.3657663e-01  4.6327189e-02\n","  -1.8461442e-02  3.9001420e-01 -1.7556681e-01  2.9329288e-01\n","   2.8054413e-01  4.2602103e-02  7.6684281e-02 -1.0697205e-02\n","  -1.6956966e-02 -2.2006048e-01 -3.3867371e-01 -6.7516112e-01\n","   5.7703471e-01  5.9303075e-02 -1.4222764e-02 -2.1772644e-01\n","  -2.5659708e-02  3.3504893e-03  3.6065299e-02 -4.9713779e-02\n","   6.2392350e-02  1.8749295e-01  2.8446293e-01  5.9988910e-01\n","   3.2160044e-01 -1.9936360e-01  1.7904608e-01]]\n","WARNING:tensorflow:10 out of the last 322 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe89f13f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\n"," ---------------------------------------- dense layer ---------------------------------------- \n","\n","[[0.84990764]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-dUDSg7VeCzM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616332376762,"user_tz":-330,"elapsed":829,"user":{"displayName":"Venkat V","photoUrl":"","userId":"03296853045304134225"}},"outputId":"dc9f02b0-1899-4746-e3ec-4f1580c21604"},"source":["decode_review(x_test[25], y_test[25])\n","print(f'Predicted sentiment: {y_pred[25][0]}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Review: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> this is a movie about the music that is currently being played in <UNK> <UNK> was the center of the two old world <UNK> the <UNK> empire and the <UNK> empire today it is a <UNK> of almost 10 million so it is to no ones surprise that a lot of music is being played in <UNK> with a great variety of voices styles and influences from everywhere on the globe it is turkish music of course and i was fascinated by turkish music ever since i bought my first record long time ago the movie features different singers <UNK> and bands spoken comments from the musicians nicely illustrate the music being played and the social context in modern turkey for my perspective the most interesting comments were from furthermore the movies shows urban scenery mainly from <UNK> which is very pleasant to watch br br crossing the bridge is listed as a documentary and it includes music from <UNK> e g and <UNK> other important topics are <UNK> such as turkish jazz music or music of the and <UNK> br br this movie is strongly recommended for lovers of the music and culture of turkey the <UNK> the eastern <UNK> and the middle east it may also be worthwhile for those with a keen interest in the global effects of musical styles such as rock and roll or hip hop\n","Actual Sentiment: 1\n","Predicted sentiment: 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H2ABHMEM6jY0"},"source":["#Conclusion\n","Sentiment classification task on the IMDB dataset, on test dataset,\n","Accuracy: > 90%\n","\n","*   F1-score: > 90%\n","*   Loss of 0.25"]},{"cell_type":"code","metadata":{"id":"Tskt_1npeCzP"},"source":[""],"execution_count":null,"outputs":[]}]}